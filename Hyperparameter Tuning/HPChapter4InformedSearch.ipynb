{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 0.1/1.6 MB 1.2 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 0.6/1.6 MB 4.4 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.3/1.6 MB 6.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.6/1.6 MB 6.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from hyperopt) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from hyperopt) (1.11.3)\n",
      "Requirement already satisfied: six in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from hyperopt) (3.1)\n",
      "Requirement already satisfied: future in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from hyperopt) (0.18.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from hyperopt) (4.65.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from hyperopt) (2.2.1)\n",
      "Collecting py4j (from hyperopt)\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "     ---------------------------------------- 0.0/200.5 kB ? eta -:--:--\n",
      "     ------------------------------------- 200.5/200.5 kB 11.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from tqdm->hyperopt) (0.4.6)\n",
      "Installing collected packages: py4j, hyperopt\n",
      "Successfully installed hyperopt-0.2.7 py4j-0.10.9.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: fairness 0.1.8 has a non-standard dependency specifier BlackBoxAuditing>=0.1.26ggplot. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of fairness or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tpot\n",
      "  Downloading TPOT-0.12.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy>=1.16.3 in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from tpot) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.1 in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from tpot) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from tpot) (1.3.0)\n",
      "Collecting deap>=1.2 (from tpot)\n",
      "  Downloading deap-1.4.1.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.2/1.1 MB 2.6 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 0.5/1.1 MB 4.6 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 0.8/1.1 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.1/1.1 MB 5.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting update-checker>=0.16 (from tpot)\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from tpot) (4.65.0)\n",
      "Collecting stopit>=1.1.1 (from tpot)\n",
      "  Downloading stopit-1.1.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from tpot) (2.1.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from tpot) (1.2.0)\n",
      "Collecting xgboost>=1.1.0 (from tpot)\n",
      "  Downloading xgboost-2.0.2-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->tpot) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->tpot) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->tpot) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.0->tpot) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from tqdm>=4.36.1->tpot) (0.4.6)\n",
      "Requirement already satisfied: requests>=2.3.0 in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from update-checker>=0.16->tpot) (2.31.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->tpot) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fahad\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2023.7.22)\n",
      "Downloading TPOT-0.12.1-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.4/87.4 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading xgboost-2.0.2-py3-none-win_amd64.whl (99.8 MB)\n",
      "   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/99.8 MB 14.5 MB/s eta 0:00:07\n",
      "   ---------------------------------------- 1.1/99.8 MB 13.9 MB/s eta 0:00:08\n",
      "    --------------------------------------- 1.7/99.8 MB 15.6 MB/s eta 0:00:07\n",
      "    --------------------------------------- 2.2/99.8 MB 13.8 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 2.8/99.8 MB 13.8 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 3.5/99.8 MB 13.0 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 4.1/99.8 MB 13.2 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 4.9/99.8 MB 13.5 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 5.5/99.8 MB 13.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 6.1/99.8 MB 13.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 6.7/99.8 MB 13.3 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 7.3/99.8 MB 13.3 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 7.8/99.8 MB 13.5 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 8.5/99.8 MB 13.6 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 9.1/99.8 MB 13.8 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 9.6/99.8 MB 13.7 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 10.3/99.8 MB 13.4 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 10.7/99.8 MB 13.4 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 11.4/99.8 MB 13.4 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 12.1/99.8 MB 13.6 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 12.8/99.8 MB 13.6 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 13.4/99.8 MB 13.6 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 14.1/99.8 MB 13.9 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 14.8/99.8 MB 13.6 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 15.2/99.8 MB 13.6 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 15.8/99.8 MB 13.6 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 16.5/99.8 MB 13.6 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 17.2/99.8 MB 13.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 17.8/99.8 MB 13.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 18.5/99.8 MB 13.4 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 19.2/99.8 MB 13.4 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 19.9/99.8 MB 13.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 20.6/99.8 MB 13.6 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 21.0/99.8 MB 13.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 21.0/99.8 MB 13.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 21.0/99.8 MB 13.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 21.0/99.8 MB 13.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 21.0/99.8 MB 10.9 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 21.6/99.8 MB 10.9 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 22.2/99.8 MB 10.9 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 22.6/99.8 MB 10.7 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 23.2/99.8 MB 10.9 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 23.7/99.8 MB 10.9 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 24.2/99.8 MB 10.7 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 24.8/99.8 MB 10.7 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 25.6/99.8 MB 10.9 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 26.2/99.8 MB 10.7 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 26.8/99.8 MB 10.9 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 27.4/99.8 MB 10.9 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 28.1/99.8 MB 10.9 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 28.8/99.8 MB 10.9 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 29.5/99.8 MB 10.7 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 30.1/99.8 MB 10.9 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 30.7/99.8 MB 10.7 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 31.3/99.8 MB 13.4 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 31.9/99.8 MB 13.4 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 32.5/99.8 MB 13.4 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 33.2/99.8 MB 13.6 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 33.8/99.8 MB 13.6 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 34.4/99.8 MB 13.9 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 34.9/99.8 MB 13.9 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 35.6/99.8 MB 13.9 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 36.3/99.8 MB 13.9 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 37.0/99.8 MB 13.6 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 37.5/99.8 MB 13.9 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 38.2/99.8 MB 13.9 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 38.6/99.8 MB 13.6 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 39.1/99.8 MB 13.4 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 39.8/99.8 MB 13.4 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 40.4/99.8 MB 13.4 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 41.0/99.8 MB 13.6 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 41.6/99.8 MB 13.4 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 42.1/99.8 MB 13.1 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 42.6/99.8 MB 13.1 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 43.2/99.8 MB 13.1 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 43.8/99.8 MB 12.8 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 44.4/99.8 MB 13.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 45.0/99.8 MB 12.8 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 45.5/99.8 MB 12.8 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 45.9/99.8 MB 12.6 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 46.4/99.8 MB 12.9 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 47.0/99.8 MB 12.4 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 47.7/99.8 MB 12.6 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 48.3/99.8 MB 12.4 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 48.9/99.8 MB 12.4 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 49.4/99.8 MB 12.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 50.0/99.8 MB 12.8 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 50.6/99.8 MB 12.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 51.1/99.8 MB 12.9 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 51.7/99.8 MB 12.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 52.0/99.8 MB 12.4 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 52.6/99.8 MB 12.4 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 53.1/99.8 MB 12.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 53.7/99.8 MB 12.4 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 54.4/99.8 MB 12.4 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 54.8/99.8 MB 12.4 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 55.3/99.8 MB 12.1 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 55.9/99.8 MB 12.1 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 56.4/99.8 MB 12.3 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 56.9/99.8 MB 12.4 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 57.6/99.8 MB 12.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 58.2/99.8 MB 12.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 58.7/99.8 MB 12.4 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 59.3/99.8 MB 12.4 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 59.9/99.8 MB 12.4 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 60.5/99.8 MB 12.4 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 61.0/99.8 MB 12.4 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 61.7/99.8 MB 12.6 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 62.4/99.8 MB 12.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 62.9/99.8 MB 12.6 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 63.4/99.8 MB 12.6 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 64.0/99.8 MB 12.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 64.5/99.8 MB 12.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 65.2/99.8 MB 12.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 65.9/99.8 MB 12.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 66.5/99.8 MB 12.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 66.9/99.8 MB 12.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 67.4/99.8 MB 12.6 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 68.0/99.8 MB 12.6 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 68.6/99.8 MB 12.4 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 69.1/99.8 MB 12.4 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 69.6/99.8 MB 12.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 69.9/99.8 MB 12.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 70.2/99.8 MB 11.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 70.6/99.8 MB 11.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 70.9/99.8 MB 11.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 71.1/99.8 MB 11.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 71.4/99.8 MB 10.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 71.5/99.8 MB 10.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 71.7/99.8 MB 10.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 71.8/99.8 MB 9.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 71.9/99.8 MB 9.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 72.0/99.8 MB 9.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 72.2/99.8 MB 9.1 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 72.3/99.8 MB 8.7 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 72.3/99.8 MB 8.4 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 72.4/99.8 MB 8.1 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 72.4/99.8 MB 7.8 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 72.5/99.8 MB 7.6 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 72.5/99.8 MB 7.4 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 72.6/99.8 MB 7.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 72.6/99.8 MB 7.0 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 72.7/99.8 MB 6.7 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 72.7/99.8 MB 6.5 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 72.8/99.8 MB 6.4 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 72.8/99.8 MB 6.1 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 72.9/99.8 MB 6.0 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 72.9/99.8 MB 5.8 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 73.0/99.8 MB 5.7 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 73.1/99.8 MB 5.6 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 73.2/99.8 MB 5.5 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 73.3/99.8 MB 5.4 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 73.4/99.8 MB 5.2 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 73.5/99.8 MB 5.2 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 73.7/99.8 MB 5.1 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 73.9/99.8 MB 5.0 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 74.0/99.8 MB 4.9 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 74.2/99.8 MB 4.8 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 74.4/99.8 MB 4.8 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 74.5/99.8 MB 4.7 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 74.8/99.8 MB 4.6 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 75.0/99.8 MB 4.6 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 75.3/99.8 MB 4.5 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 75.5/99.8 MB 4.5 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 75.8/99.8 MB 4.4 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 76.1/99.8 MB 4.3 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 76.3/99.8 MB 4.3 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 76.6/99.8 MB 4.3 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 77.0/99.8 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 77.3/99.8 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 77.6/99.8 MB 4.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 77.9/99.8 MB 4.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 78.2/99.8 MB 4.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 78.6/99.8 MB 4.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 79.0/99.8 MB 4.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 79.3/99.8 MB 4.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 79.8/99.8 MB 4.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 80.1/99.8 MB 4.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 80.5/99.8 MB 4.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 80.8/99.8 MB 4.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 81.2/99.8 MB 4.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 81.5/99.8 MB 4.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 81.9/99.8 MB 4.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 82.4/99.8 MB 4.4 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 82.7/99.8 MB 4.7 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 83.2/99.8 MB 5.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 83.6/99.8 MB 6.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 84.1/99.8 MB 7.0 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 84.6/99.8 MB 7.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 85.1/99.8 MB 7.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 85.6/99.8 MB 8.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 86.1/99.8 MB 8.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 86.6/99.8 MB 8.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 87.0/99.8 MB 8.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 87.5/99.8 MB 9.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 88.0/99.8 MB 9.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 88.5/99.8 MB 9.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 89.1/99.8 MB 9.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 90.3/99.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 90.9/99.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 91.4/99.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 91.8/99.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 92.3/99.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 92.9/99.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 93.5/99.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 94.1/99.8 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 94.7/99.8 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 95.3/99.8 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 95.9/99.8 MB 11.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 96.5/99.8 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 97.0/99.8 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  97.4/99.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  97.9/99.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.4/99.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.9/99.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.2/99.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 99.8/99.8 MB 9.8 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: deap, stopit\n",
      "  Building wheel for deap (setup.py): started\n",
      "  Building wheel for deap (setup.py): finished with status 'done'\n",
      "  Created wheel for deap: filename=deap-1.4.1-py3-none-any.whl size=97348 sha256=217a481908513c383dc51aaf6e73133f9a2b97f02c664777f988ad6546cc5d1b\n",
      "  Stored in directory: c:\\users\\fahad\\appdata\\local\\pip\\cache\\wheels\\f8\\64\\b8\\65eacfbff3024ae2e2beb22e691d5c8abb89fbd863b8049b5f\n",
      "  Building wheel for stopit (setup.py): started\n",
      "  Building wheel for stopit (setup.py): finished with status 'done'\n",
      "  Created wheel for stopit: filename=stopit-1.1.2-py3-none-any.whl size=12020 sha256=3fb58643eeb55155950d1f9b0607c14c9ecd6166b7299c77d73cee228b09c22f\n",
      "  Stored in directory: c:\\users\\fahad\\appdata\\local\\pip\\cache\\wheels\\da\\77\\2d\\adbc56bc4db95ad80c6d4e71cd69e2d9d122174904342e3f7f\n",
      "Successfully built deap stopit\n",
      "Installing collected packages: stopit, deap, xgboost, update-checker, tpot\n",
      "Successfully installed deap-1.4.1 stopit-1.1.2 tpot-0.12.1 update-checker-0.18.0 xgboost-2.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: fairness 0.1.8 has a non-standard dependency specifier BlackBoxAuditing>=0.1.26ggplot. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of fairness or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "creadit_data = pd.read_csv('../Hyperparameter Tuning/Dataset/credit-card-full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
       "1   2     120000    2          2         2   26     -1      2      0      0   \n",
       "2   3      90000    2          2         2   34      0      0      0      0   \n",
       "3   4      50000    2          2         1   37      0      0      0      0   \n",
       "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...          0          0          0         0       689         0   \n",
       "1  ...       3272       3455       3261         0      1000      1000   \n",
       "2  ...      14331      14948      15549      1518      1500      1000   \n",
       "3  ...      28314      28959      29547      2000      2019      1200   \n",
       "4  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0         0         0         0                           1  \n",
       "1      1000         0      2000                           1  \n",
       "2      1000      1000      5000                           0  \n",
       "3      1100      1069      1000                           0  \n",
       "4      9000       689       679                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creadit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = creadit_data.drop('default payment next month', axis=1)\n",
    "y = creadit_data['default payment next month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coarse to Fine Tuning\n",
    "\n",
    "This is a markdown cell used to describe and document the workflow.\n",
    "\n",
    "## A basic informed search methodology:\n",
    "\n",
    "Start out with a rough, random approach and iteratively refine your search.\n",
    "\n",
    "The process is:\n",
    "\n",
    "1. Random search\n",
    "2. Find promising areas\n",
    "3. Grid search in the smaller area\n",
    "4. Continue until optimal score obtained\n",
    "\n",
    "You could substitute (3) with further random searches before the grid search\n",
    "You could also substitute step 3 with further random searches before the grid search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes in Hyperparameter Tuning\n",
    "\n",
    "We can apply this logic to hyperparameter tuning:\n",
    "\n",
    "1. Pick a hyperparameter combination\n",
    "2. Build a model\n",
    "3. Get new evidence (the score of the model)\n",
    "4. Update our beliefs and choose better hyperparameters next round\n",
    "\n",
    "Bayesian hyperparameter tuning is very new but quite popular for larger and more complex hyperparameter tuning tasks as they work well to find optimal hyperparameter combinations in these situations.\n",
    "We can apply this logic to hyperparameter tuning:\n",
    "\n",
    ". Pick a hyperparameter combination\n",
    "\n",
    ". Build a model\n",
    "\n",
    ". Get new evidence (the score of the model)\n",
    ". Update our beliefs and chose better hyperparameters next round\n",
    "Bayesian hyperparameter tuning is very new but quite popular for larger and more complex\n",
    "hyperparameter tuning tasks as they work well to find optimal hyperparameter combinations\n",
    "in these situations\n",
    "\n",
    "Bayesian hyperparameter tuning is very new but quite popular for larger and more\n",
    "complex hyperparameter tuning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 2, 10, 2),\n",
    "    'min_samples_leaf': hp.uniform('min_samples_leaf', 2, 8, 2),\n",
    "    'learning_rate': hp.loguniform('learning_rate', 0.01, 1, 55)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    params = {\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'min_samples_leaf': int(params['min_samples_leaf']),\n",
    "        'learning_rate': params['learning_rate']\n",
    "    }\n",
    "    gbm_clf = GradientBoostingClassifier(n_estimators=100, **params, random_state=42)\n",
    "    best_score = cross_val_score(gbm_clf, X_train, y_train, scoring='accuracy', cv=5, n_jobs=-1).mean()\n",
    "    loss = 1 - best_score\n",
    "    write_results(best_score, params, iteration)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.random.mtrand.RandomState' object has no attribute 'integers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fahad\\Development\\BSMM-8740-1\\Hyperparameter Tuning\\HPChapter4InformedSearch.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fahad/Development/BSMM-8740-1/Hyperparameter%20Tuning/HPChapter4InformedSearch.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m best_result \u001b[39m=\u001b[39m fmin(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fahad/Development/BSMM-8740-1/Hyperparameter%20Tuning/HPChapter4InformedSearch.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     fn\u001b[39m=\u001b[39mobjective,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fahad/Development/BSMM-8740-1/Hyperparameter%20Tuning/HPChapter4InformedSearch.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     space\u001b[39m=\u001b[39mspace,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fahad/Development/BSMM-8740-1/Hyperparameter%20Tuning/HPChapter4InformedSearch.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     max_evals\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fahad/Development/BSMM-8740-1/Hyperparameter%20Tuning/HPChapter4InformedSearch.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     rstate\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mRandomState(\u001b[39m42\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fahad/Development/BSMM-8740-1/Hyperparameter%20Tuning/HPChapter4InformedSearch.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     algo\u001b[39m=\u001b[39mtpe\u001b[39m.\u001b[39msuggest\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fahad/Development/BSMM-8740-1/Hyperparameter%20Tuning/HPChapter4InformedSearch.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\fahad\\anaconda3\\Lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39mexhaust()\n\u001b[0;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\fahad\\anaconda3\\Lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_evals \u001b[39m-\u001b[39m n_done, block_until_done\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39masynchronous)\n\u001b[0;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\fahad\\anaconda3\\Lib\\site-packages\\hyperopt\\fmin.py:279\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[0;32m    274\u001b[0m \u001b[39m# Based on existing trials and the domain, use `algo` to probe in\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[39m# new hp points. Save the results of those inspections into\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[39m# `new_trials`. This is the core of `run`, all the rest is just\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[39m# processes orchestration\u001b[39;00m\n\u001b[0;32m    278\u001b[0m new_trials \u001b[39m=\u001b[39m algo(\n\u001b[1;32m--> 279\u001b[0m     new_ids, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdomain, trials, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrstate\u001b[39m.\u001b[39mintegers(\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m31\u001b[39m \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m    280\u001b[0m )\n\u001b[0;32m    281\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(new_ids) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(new_trials)\n\u001b[0;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(new_trials):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.random.mtrand.RandomState' object has no attribute 'integers'"
     ]
    }
   ],
   "source": [
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    max_evals=500,\n",
    "    rstate=np.random.RandomState(42),\n",
    "    algo=tpe.suggest\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In genetic evolution in the real world, we have the following process:\n",
    "\n",
    "1. There are many creatures existing ('offspring')\n",
    "2. The strongest creatures survive and pair off\n",
    "3. There is some 'crossover' as they form offspring\n",
    "4. There are random mutations to some of the offspring\n",
    "    - These mutations sometimes help give some offspring an advantage\n",
    "    \n",
    "5. Go back to (1)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply the same idea to hyperparameter tuning:\n",
    "\n",
    "1. We can create some models (that have hyperparameter settings)\n",
    "\n",
    "2. We can pick the best (by our scoring function)\n",
    ". These are the ones that 'survive'\n",
    "\n",
    "3. We can create new models that are similar to the best ones\n",
    "\n",
    "4. We add in some randomness so we don't reach a local optimum\n",
    "\n",
    "5. Repeat until we are happy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key arguments to a TPOT classifier are:\n",
    "\n",
    "- `generations`: Iterations to run training for.\n",
    "- `population_size`: The number of models to keep after each iteration.\n",
    "- `offspring_size`: Number of models to produce in each iteration.\n",
    "- `mutation_rate`: The proportion of pipelines to apply randomness to.\n",
    "- `crossover_rate`: The proportion of pipelines to breed each iteration.\n",
    "- `scoring`: The function to determine the best models.\n",
    "- `cv`: Cross-validation strategy to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fahad\\anaconda3\\Lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot = TPOTClassifier(\n",
    "    generations=3,\n",
    "    population_size=5,\n",
    "    verbosity=2,\n",
    "    offspring_size=10,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579fbdf0ee96472ba54fa1326fedb629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/35 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8216888888888889\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.8220444444444445\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.8220444444444445\n",
      "\n",
      "Best pipeline: ExtraTreesClassifier(input_matrix, bootstrap=True, criterion=entropy, max_features=0.6000000000000001, min_samples_leaf=7, min_samples_split=3, n_estimators=100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TPOTClassifier(generations=3, offspring_size=10, population_size=5,\n",
       "               random_state=42, scoring=&#x27;accuracy&#x27;, verbosity=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TPOTClassifier</label><div class=\"sk-toggleable__content\"><pre>TPOTClassifier(generations=3, offspring_size=10, population_size=5,\n",
       "               random_state=42, scoring=&#x27;accuracy&#x27;, verbosity=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TPOTClassifier(generations=3, offspring_size=10, population_size=5,\n",
       "               random_state=42, scoring='accuracy', verbosity=2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8172"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
